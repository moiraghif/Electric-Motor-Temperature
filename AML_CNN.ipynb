{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gki-kdSYyMq_"
   },
   "source": [
    "```\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#connect\").click() \n",
    "}\n",
    "setInterval(ConnectButton,60000);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vb3X0xFRUQXW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZko5hYs60sN"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade tqdm\n",
    "!pip install parameter-sherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SQ6LXKCwUllM",
    "outputId": "4f41d711-b325-4e02-d45c-c8e0265c57e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import sherpa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vLeWHW389VX"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDOxJCCLUwS2"
   },
   "outputs": [],
   "source": [
    "path = \"drive/My Drive/AML/\"\n",
    "#path = \"\"\n",
    "\n",
    "df = pd.read_csv(path + \"pmsm_temperature_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QspAjGn-6lFX"
   },
   "outputs": [],
   "source": [
    "df_sep = [df[df\n",
    "             .profile_id==profile]\n",
    "          .drop(['profile_id','torque','stator_yoke',\n",
    "                 'stator_tooth','stator_winding'],axis=1)\n",
    "          .reset_index(drop=True) for profile in df.profile_id.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rw4gyRTEnjHj"
   },
   "outputs": [],
   "source": [
    "def outputSize(in_size, kernel_size, stride, padding):\n",
    "  output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
    "  return(output)\n",
    "\n",
    "class CNN_Net_2(nn.Module):\n",
    "    def __init__(self, batch, in_c, out, \n",
    "                 kernel1, kernel2, kernel3, kernel4, \n",
    "                 #padding1, padding2, padding3, padding4, \n",
    "                 stride1, stride2, stride3, stride4):\n",
    "        super(CNN_Net_2, self).__init__()\n",
    "        self.batch_size = 1\n",
    "        self.in_c = in_c\n",
    "        l0 = 60\n",
    "        l1 = outputSize(l0,kernel1,stride1,0)\n",
    "        l2 = outputSize(l1,kernel2,stride2,0)\n",
    "        l3 = outputSize(l2,kernel3,stride3,0)\n",
    "        l4 = outputSize(l3,kernel4,stride4,0)\n",
    "        #print(l4)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels= in_c, \n",
    "                               out_channels= 16, \n",
    "                               kernel_size= kernel1,\n",
    "                               stride= stride1,\n",
    "                               padding=0)    \n",
    "        self.pool1 = nn.MaxPool1d(kernel2,stride=stride2,padding=0) \n",
    "        self.conv2 = nn.Conv1d(16,8,kernel3,stride=stride3,padding=0)\n",
    "        self.pool2 = nn.MaxPool1d(kernel4,stride=stride4,padding=0)\n",
    "        self.fc1 = nn.Linear(8*l4, 100)\n",
    "        self.fc2 = nn.Linear(100, out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, _ = x.shape\n",
    "        x =  self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(batch_size, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        return  self.fc2(x)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:       # Get the products\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zq9xOY0AVoE8"
   },
   "outputs": [],
   "source": [
    "def sliding_window(dataset, target_var, inp, out, shuffle=True):\n",
    "    while True:\n",
    "        for X in dataset:\n",
    "            target = X[[target_var]]\n",
    "            num_features = len(X.columns)\n",
    "            \n",
    "            indice = list(range(inp + out, X.shape[0]))\n",
    "            \n",
    "            if shuffle:\n",
    "                np.random.shuffle(indice)\n",
    "            for i in indice:\n",
    "                features = X.iloc[i-inp-out:i-out,].values.reshape(inp,num_features)\n",
    "                pred = target.iloc[i:i+out]\n",
    "\n",
    "                yield np.array(features), np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfgsQZYi-yVH"
   },
   "outputs": [],
   "source": [
    "FEATURES = [0, 1, 2, 3, 4, 5, 6]\n",
    "TARGET = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuIvEM63-07a"
   },
   "outputs": [],
   "source": [
    "def dataloader(data, length, shuffle=True, out=1):\n",
    "    while True:\n",
    "    # genera una lista di (i_serie, i_obs)\n",
    "        tuples = [[(df_i, i) for i, x in enumerate(data[df_i]) if i >= length + out]\n",
    "                  for df_i, _ in enumerate(data)]\n",
    "        tuples = sum(tuples, [])  # flattenizza\n",
    "        # shuffle\n",
    "        if shuffle:\n",
    "            np.random.shuffle(tuples)\n",
    "\n",
    "        # yielda le osservazioni\n",
    "        for df_i, i in tuples:\n",
    "            X_lagged = data[df_i][(i - length - out):(i - out), FEATURES + TARGET]\n",
    "            y = data[df_i][(i-out):(i), TARGET]\n",
    "            yield X_lagged, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5Zsp_d4oDoi"
   },
   "outputs": [],
   "source": [
    "train_min = df[~df.profile_id.isin([4, 8, 16, 24, 32, 40, 48, 51, 35, 42])].drop(['profile_id','torque',\n",
    "                                                                                 'stator_yoke','stator_tooth',\n",
    "                                                                                  'stator_winding'], \n",
    "                                                                                 axis=1).min()\n",
    "train_max = df[~df.profile_id.isin([4, 8, 16, 24, 32, 40, 48, 51, 35, 42])].drop(['profile_id','torque',\n",
    "                                                                                 'stator_yoke','stator_tooth',\n",
    "                                                                                  'stator_winding'], \n",
    "                                                                                 axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gBjhn7q5h21R",
    "outputId": "285cae3a-b3da-4c59-a4cf-1e32bb5f06c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "df_train = [(df_sep[i] - train_min)/(train_max - train_min)\\\n",
    "            for i in list(range(0,52)) if i not in [4, 8, 16, 24, 32, \n",
    "                                                    40, 48, 51, #val\n",
    "                                                    35, 42]] #test\n",
    "\n",
    "df_val = [(df_sep[i] - train_min)/(train_max - train_min)\\\n",
    "          for i in [4, 8, 16, 24, 32, 40, 48, 51]]\n",
    "\n",
    "df_test = [(df_sep[i] - train_min)/(train_max - train_min) for i in [35, 42]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3T0EvxOkvzEB"
   },
   "outputs": [],
   "source": [
    "parameters = [sherpa.Continuous('lr',[0.005,0.05]),\n",
    "              sherpa.Discrete('kernel1',[1,5]),\n",
    "              sherpa.Discrete('kernel2',[1,5]),\n",
    "              sherpa.Discrete('kernel3',[1,5]),\n",
    "              sherpa.Discrete('kernel4',[1,5]),\n",
    "              sherpa.Discrete('stride1',[1,3]),\n",
    "              sherpa.Discrete('stride2',[1,3]),\n",
    "              sherpa.Discrete('stride3',[1,3]),\n",
    "              sherpa.Discrete('stride4',[1,3]),\n",
    "              #sherpa.Discrete('padding1',[0,1]),\n",
    "              #sherpa.Discrete('padding2',[0,1]),\n",
    "              #sherpa.Discrete('padding3',[0,1]),\n",
    "              #sherpa.Discrete('padding4',[0,1]),\n",
    "              sherpa.Choice('batch_size',[512, 1024, 2048])]\n",
    "\n",
    "alg = sherpa.algorithms.bayesian_optimization.GPyOpt(max_concurrent=1,\n",
    "                                         model_type='GP',\n",
    "                                         acquisition_type='EI',\n",
    "                                         max_num_trials=100)\n",
    "\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,\n",
    "                     lower_is_better=True,\n",
    "                     disable_dashboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KjcWnilcv--D",
    "outputId": "b3615998-b3ed-4e5e-a7b0-e93d6c2156af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0215613: 100%|██████████| 753/753 [00:17<00:00, 42.38it/s]\n",
      "  0%|          | 0/1506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.025155118690731428 and confs: {'lr': 0.006999504608353264, 'kernel1': 1, 'kernel2': 2, 'kernel3': 1, 'kernel4': 3, 'stride1': 2, 'stride2': 2, 'stride3': 2, 'stride4': 1, 'batch_size': 1024}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1506 Loss:0.3127785: 100%|██████████| 1506/1506 [00:25<00:00, 21.93it/s]\n",
      "Epoch:753 Loss:0.0974553: 100%|██████████| 753/753 [00:29<00:00, 25.93it/s]\n",
      "Epoch:377 Loss:0.0924276: 100%|██████████| 377/377 [00:19<00:00,  6.04it/s]\n",
      "  0%|          | 0/753 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.010386161364523014 and confs: {'lr': 0.029963974431836453, 'kernel1': 2, 'kernel2': 3, 'kernel3': 4, 'kernel4': 3, 'stride1': 2, 'stride2': 1, 'stride3': 1, 'stride4': 1, 'batch_size': 2048}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0437576: 100%|██████████| 753/753 [00:26<00:00, 11.74it/s]\n",
      "Epoch:1506 Loss:0.047571: 100%|██████████| 1506/1506 [00:26<00:00, 21.67it/s]\n",
      "Epoch:1506 Loss:0.0327867: 100%|██████████| 1506/1506 [00:20<00:00, 74.64it/s]\n",
      "Epoch:753 Loss:0.083705: 100%|██████████| 753/753 [00:24<00:00, 30.38it/s]\n",
      "Epoch:753 Loss:0.0070481: 100%|██████████| 753/753 [00:23<00:00, 12.28it/s]\n",
      "  0%|          | 0/377 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.0034411715780612697 and confs: {'lr': 0.02389786350581449, 'kernel1': 3, 'kernel2': 2, 'kernel3': 1, 'kernel4': 2, 'stride1': 1, 'stride2': 2, 'stride3': 2, 'stride4': 1, 'batch_size': 1024}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:377 Loss:0.0734249: 100%|██████████| 377/377 [00:25<00:00,  6.02it/s]\n",
      "Epoch:377 Loss:0.0330829: 100%|██████████| 377/377 [00:24<00:00,  6.11it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0323777: 100%|██████████| 753/753 [00:17<00:00, 42.33it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0139702: 100%|██████████| 753/753 [00:18<00:00, 41.00it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0340362: 100%|██████████| 753/753 [00:22<00:00, 12.47it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.2724843: 100%|██████████| 753/753 [00:24<00:00, 30.53it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0623468: 100%|██████████| 753/753 [00:22<00:00, 11.25it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.1240894: 100%|██████████| 753/753 [00:18<00:00, 41.55it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.2358336: 100%|██████████| 753/753 [00:24<00:00, 30.94it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0206643: 100%|██████████| 753/753 [00:25<00:00, 12.10it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:377 Loss:0.040546: 100%|██████████| 377/377 [00:19<00:00,  8.57it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:377 Loss:0.0108369: 100%|██████████| 377/377 [00:21<00:00,  6.41it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0105026: 100%|██████████| 753/753 [00:22<00:00, 12.58it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0053692: 100%|██████████| 753/753 [00:22<00:00, 12.35it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.002358750710606835 and confs: {'lr': 0.016145967088417312, 'kernel1': 3.0, 'kernel2': 3.0, 'kernel3': 1.0, 'kernel4': 2.0, 'stride1': 1.0, 'stride2': 2.0, 'stride3': 2.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0040975: 100%|██████████| 753/753 [00:23<00:00, 12.15it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.0013972296104484206 and confs: {'lr': 0.011518574068135267, 'kernel1': 3.0, 'kernel2': 3.0, 'kernel3': 1.0, 'kernel4': 2.0, 'stride1': 1.0, 'stride2': 2.0, 'stride3': 2.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0057315: 100%|██████████| 753/753 [00:23<00:00, 12.19it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0049947: 100%|██████████| 753/753 [00:23<00:00, 12.11it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0043574: 100%|██████████| 753/753 [00:22<00:00, 12.46it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.004286: 100%|██████████| 753/753 [00:22<00:00, 12.46it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.0012754435066064545 and confs: {'lr': 0.005, 'kernel1': 3.0, 'kernel2': 3.0, 'kernel3': 1.0, 'kernel4': 2.0, 'stride1': 1.0, 'stride2': 2.0, 'stride3': 2.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0052986: 100%|██████████| 753/753 [00:23<00:00, 12.13it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0085195: 100%|██████████| 753/753 [00:22<00:00, 12.51it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0047921: 100%|██████████| 753/753 [00:22<00:00, 12.62it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.006576: 100%|██████████| 753/753 [00:22<00:00, 12.60it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0054238: 100%|██████████| 753/753 [00:22<00:00, 32.77it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0057109: 100%|██████████| 753/753 [00:22<00:00, 12.79it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0068072: 100%|██████████| 753/753 [00:22<00:00, 12.63it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0043748: 100%|██████████| 753/753 [00:22<00:00, 12.42it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0069588: 100%|██████████| 753/753 [00:23<00:00, 12.17it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0070014: 100%|██████████| 753/753 [00:22<00:00, 12.49it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0044901: 100%|██████████| 753/753 [00:23<00:00, 12.36it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0054021: 100%|██████████| 753/753 [00:22<00:00, 12.29it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0030436: 100%|██████████| 753/753 [00:22<00:00, 12.35it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.0005942704971403521 and confs: {'lr': 0.005, 'kernel1': 3.0, 'kernel2': 4.0, 'kernel3': 1.0, 'kernel4': 1.0, 'stride1': 1.0, 'stride2': 2.0, 'stride3': 3.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0043217: 100%|██████████| 753/753 [00:22<00:00, 12.44it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.000525348732365468 and confs: {'lr': 0.005, 'kernel1': 3.0, 'kernel2': 4.0, 'kernel3': 1.0, 'kernel4': 1.0, 'stride1': 1.0, 'stride2': 2.0, 'stride3': 3.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0024001: 100%|██████████| 753/753 [00:23<00:00, 12.29it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.00042963263338907344 and confs: {'lr': 0.005, 'kernel1': 3.0, 'kernel2': 4.0, 'kernel3': 1.0, 'kernel4': 1.0, 'stride1': 1.0, 'stride2': 1.0, 'stride3': 3.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0031521: 100%|██████████| 753/753 [00:23<00:00, 12.14it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0027223: 100%|██████████| 753/753 [00:23<00:00, 31.64it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0035167: 100%|██████████| 753/753 [00:23<00:00, 11.95it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0032475: 100%|██████████| 753/753 [00:23<00:00, 12.18it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0033002: 100%|██████████| 753/753 [00:23<00:00, 12.43it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0067488: 100%|██████████| 753/753 [00:17<00:00, 42.46it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0029787: 100%|██████████| 753/753 [00:22<00:00, 12.74it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0040991: 100%|██████████| 753/753 [00:22<00:00, 12.68it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:377 Loss:0.0212842: 100%|██████████| 377/377 [00:15<00:00, 23.91it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0031815: 100%|██████████| 753/753 [00:22<00:00, 12.39it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0061765: 100%|██████████| 753/753 [00:22<00:00, 12.47it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0038809: 100%|██████████| 753/753 [00:23<00:00, 11.33it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0046152: 100%|██████████| 753/753 [00:25<00:00, 30.01it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0035934: 100%|██████████| 753/753 [00:24<00:00, 11.96it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.003006: 100%|██████████| 753/753 [00:25<00:00, 29.66it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0022973: 100%|██████████| 753/753 [00:25<00:00, 29.53it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0044529: 100%|██████████| 753/753 [00:25<00:00, 29.51it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0018474: 100%|██████████| 753/753 [00:25<00:00, 11.78it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.0004233472185203098 and confs: {'lr': 0.005, 'kernel1': 3.0, 'kernel2': 3.0, 'kernel3': 1.0, 'kernel4': 1.0, 'stride1': 1.0, 'stride2': 1.0, 'stride3': 2.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0021943: 100%|██████████| 753/753 [00:25<00:00, 29.52it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Challanger with MSE on val: 0.0003349143275392701 and confs: {'lr': 0.005, 'kernel1': 3.0, 'kernel2': 3.0, 'kernel3': 1.0, 'kernel4': 1.0, 'stride1': 1.0, 'stride2': 1.0, 'stride3': 2.0, 'stride4': 1.0, 'batch_size': 1024.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:753 Loss:0.0022943: 100%|██████████| 753/753 [00:25<00:00, 29.38it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0021103: 100%|██████████| 753/753 [00:24<00:00, 12.28it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0035246: 100%|██████████| 753/753 [00:25<00:00, 29.84it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0031363: 100%|██████████| 753/753 [00:24<00:00, 30.16it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0022333: 100%|██████████| 753/753 [00:25<00:00, 29.97it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0034347: 100%|██████████| 753/753 [00:24<00:00, 30.37it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0024981: 100%|██████████| 753/753 [00:24<00:00, 30.25it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0033884: 100%|██████████| 753/753 [00:24<00:00, 12.07it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:377 Loss:0.0234315: 100%|██████████| 377/377 [00:14<00:00, 26.03it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:753 Loss:0.0045287: 100%|██████████| 753/753 [00:24<00:00, 30.64it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:1506 Loss:0.0040232: 100%|██████████| 1506/1506 [00:23<00:00, 64.27it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:1506 Loss:0.0025351: 100%|██████████| 1506/1506 [00:23<00:00, 65.38it/s]\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "Epoch:367 Loss:0.0089766:  24%|██▍       | 366/1506 [00:06<00:17, 63.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "look_back  = 60\n",
    "best_score = 99999\n",
    "feature    = 8\n",
    "\n",
    "for trial in study:\n",
    "\n",
    "    lstm = CNN_Net_2(batch=int(trial.parameters[\"batch_size\"]),\n",
    "                     in_c=feature,\n",
    "                     out = 1,\n",
    "                     kernel1=int(trial.parameters[\"kernel1\"]),\n",
    "                     kernel2=int(trial.parameters[\"kernel2\"]),\n",
    "                     kernel3=int(trial.parameters[\"kernel3\"]),\n",
    "                     kernel4=int(trial.parameters[\"kernel4\"]),\n",
    "                     stride1=int(trial.parameters[\"stride1\"]),\n",
    "                     stride2=int(trial.parameters[\"stride2\"]),\n",
    "                     stride3=int(trial.parameters[\"stride3\"]),\n",
    "                     stride4=int(trial.parameters[\"stride4\"]),\n",
    "                     #padding1=int(trial.parameters[\"padding1\"]),\n",
    "                     #padding2=int(trial.parameters[\"padding2\"]),\n",
    "                     #padding3=int(trial.parameters[\"padding3\"]),\n",
    "                     #padding4=int(trial.parameters[\"padding4\"])\n",
    "                     ).to(device)\n",
    "                     \n",
    "    losses = []\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(lstm.parameters(), lr=trial.parameters[\"lr\"])\n",
    "\n",
    "    batch_size = int(trial.parameters[\"batch_size\"])\n",
    "\n",
    "    df_length = np.sum([x.shape[0] for x in df_train])\n",
    "\n",
    "    #gen = sliding_window(df_train, \"pm\", look_back, 1)\n",
    "    gen = dataloader([df.values for df in df_train], look_back)\n",
    "    progress_bar = tqdm(range(0, df_length, batch_size))\n",
    "\n",
    "    lstm.train()\n",
    "    for b in progress_bar:\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for i in range(batch_size):\n",
    "            try:\n",
    "                X,y = next(gen)\n",
    "                X_train.append(X)\n",
    "                y_train.append(y)\n",
    "            except StopIteration:\n",
    "                #in case the datagen ends, recreate a new a one and continue\n",
    "                #it should not happen though since the the datagen\n",
    "                #should be infinite (theorically), it's more of a precaution\n",
    "                #gen = sliding_window(df_train, \"pm\", look_back, 1)\n",
    "                gen = dataloader([df.values for df in df_train], look_back)\n",
    "\n",
    "                X,y = next(gen)\n",
    "                X_train.append(X)\n",
    "                y_train.append(y)\n",
    "        \n",
    "        inpt = np.array(X_train).reshape(-1, 8, look_back)\n",
    "        target = np.array(y_train)    \n",
    "        x_batch = torch.tensor(inpt,dtype=torch.float32).to(device)  \n",
    "        y_batch = torch.tensor(target,dtype=torch.float32).to(device)\n",
    "        try:\n",
    "            output = lstm(x_batch) \n",
    "            loss = criterion(output.view(-1), y_batch.view(-1))  \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "        except:\n",
    "            print(\"something strange happened\")\n",
    "            print(inpt.shape)\n",
    "            print(x_batch.size())\n",
    "            break\n",
    "        if len(losses)>10000:\n",
    "            progress_bar.set_description(\"Epoch:\"+str(int(b/batch_size)+1)+\" Loss:\"+str(round(np.mean(losses[-1000,]),7)))\n",
    "        else:\n",
    "            progress_bar.set_description(\"Epoch:\"+str(int(b/batch_size)+1)+\" Loss:\"+str(round(np.mean(losses),7)))\n",
    "\n",
    "    #test_gen = sliding_window(df_val, \"pm\", look_back, 1)\n",
    "    test_gen = dataloader([df.values for df in df_val], look_back)\n",
    "    batch_size = 510\n",
    "\n",
    "    lstm.eval()\n",
    "    y_test = []\n",
    "    y_pred_all = []\n",
    "\n",
    "    \n",
    "    tot_len = np.sum([x.shape[0] for x in df_val])\n",
    "    for x in range(0, tot_len, batch_size):\n",
    "        X_test = []\n",
    "        for i in range(batch_size):\n",
    "            try:\n",
    "                X,y = next(test_gen)\n",
    "                X_test.append(X)\n",
    "                y_test.append(y)\n",
    "            except:\n",
    "                print(\"You somehow created an exception hahaha!\")\n",
    "                break\n",
    "\n",
    "        inpt = np.array(X_test).reshape(-1, 8, look_back)\n",
    "        x_test_batch = torch.tensor(inpt,dtype=torch.float32).to(device)  \n",
    "        #print(x_test_batch.shape)\n",
    "        y_pred = lstm(x_test_batch)\n",
    "\n",
    "        y_pred_all = np.append(y_pred_all,y_pred.cpu().detach().numpy())\n",
    "\n",
    "    y_test = np.array(y_test).reshape(-1)\n",
    "    score = np.mean((y_test - y_pred_all)**2) #MSE\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        torch.save(lstm, path + \"models/best_model_cnn\")\n",
    "        print(\"New Challanger with MSE on val:\", score, \"and confs:\", trial.parameters)\n",
    "    \n",
    "    #Sherpa PART\n",
    "    study.add_observation(trial, iteration=1, objective=score)\n",
    "    study.finalize(trial)\n",
    "    study.results.to_csv(path + \"results/AutoML_CNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHHb2__EzwYV"
   },
   "outputs": [],
   "source": [
    "best_model = torch.load(path + \"models/best_model_cnn\")\n",
    "results = pd.read_csv(path + \"results/AutoML_CNN.csv\")\n",
    "results = results[results[\"Status\"]==\"COMPLETED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wD-E06OV2Vhb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "best, = plt.plot(np.minimum.accumulate(np.array(results.Objective)),'*-')\n",
    "#actual, = plt.plot(np.array(results.Objective),'*-')\n",
    "\n",
    "#plt.legend([actual, best],\n",
    "#           ['Calculated','Best Seen']) \n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Best Seen MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUOE0O-R6s-A"
   },
   "outputs": [],
   "source": [
    "test_gen = dataloader([df_test[0].values], look_back, shuffle=False)\n",
    "\n",
    "batch_size = 510\n",
    "\n",
    "y_test = []\n",
    "y_pred_all = []\n",
    "for x in range(0, df_test[0].shape[0], batch_size):\n",
    "    X_test = []\n",
    "    for i in range(batch_size):\n",
    "        try:\n",
    "            X,y = next(test_gen)\n",
    "            X_test.append(X)\n",
    "            y_test.append(y)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    inpt = np.array(X_test).reshape(-1, 8, look_back)\n",
    "    x_test_batch = torch.tensor(inpt,dtype=torch.float32).to(device)  \n",
    "    y_pred = best_model(x_test_batch)\n",
    "\n",
    "    y_pred_all = np.append(y_pred_all,y_pred.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TETtDarx2qU4"
   },
   "outputs": [],
   "source": [
    "y_test = np.array(y_test).reshape(-1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(y_test[-10:])\n",
    "plt.plot(y_pred_all[-10:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awfQ0bE65q-Y"
   },
   "outputs": [],
   "source": [
    "np.mean(np.abs((y_test - y_pred_all)/np.abs(y_test)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AML_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
